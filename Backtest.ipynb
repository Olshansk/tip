{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e4e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this to profile: https://stackoverflow.com/questions/45893768/how-do-i-find-out-what-parts-of-my-code-are-inefficient-in-python\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521fd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import datetime\n",
    "import pprint\n",
    "\n",
    "from datetime import timedelta\n",
    "from enum import Enum, auto\n",
    "from typing import List\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ce003",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'cfg2wsKZrVNuYBJpETAs'\n",
    "DEVELOPMENT = False\n",
    "\n",
    "if DEVELOPMENT:\n",
    "    daily_metrics = pd.read_csv('SHARADAR-DAILY.csv')\n",
    "    daily_prices = pd.read_csv('SHARADAR-SEP.csv')\n",
    "else:\n",
    "    daily_metrics = pd.read_csv('SHARADAR_DAILY_3_9ffd00fad4f19bbdec75c6e670d3df83.csv')\n",
    "    daily_prices = pd.read_csv('SHARADAR_SEP_2_0bd2000858d1d8d1f48d4cdea5f8c9e2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = daily_metrics.copy()\n",
    "d2 = daily_prices[['ticker', 'date','closeadj']]\n",
    "d2.rename(columns={'closeadj': 'price'}, inplace=True)\n",
    "\n",
    "# TODO: How much data do we lose via the merge?\n",
    "daily_data = d1.merge(d2, on=['date', 'ticker'], how='inner')\n",
    "daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6cafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockUniverse(Enum):\n",
    "    SMALL = auto()  # < $1B\n",
    "    MID = auto()  # $1B - $10B\n",
    "    LARGE = auto()  # > $100B\n",
    "    \n",
    "class EvaluationMetric(Enum):\n",
    "    EV_EBIT = auto()\n",
    "    P_E = auto()\n",
    "    P_B = auto()\n",
    "    DIV_YIELD = auto()\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.value == EvaluationMetric.EV_EBIT.value:\n",
    "            return 'EV/EBIT'\n",
    "        elif self.value == EvaluationMetric.P_E.value:\n",
    "            return 'P/E'\n",
    "        elif self.value == EvaluationMetric.P_B.value:\n",
    "            return 'P/B'\n",
    "        elif self.value == EvaluationMetric.DIV_YIELD.value:\n",
    "            return '% Div Yield'\n",
    "        else:\n",
    "            raise Exception(f'Unsupported evaluation metric {metric}')\n",
    "    \n",
    "def get_closest_previous_work_day(\n",
    "    check_day: datetime.datetime,\n",
    "    holidays=holidays.US()\n",
    ") -> datetime.datetime:\n",
    "    if check_day.weekday() <= 4 and check_day not in holidays:\n",
    "        return check_day\n",
    "    offset = max(1, (check_day.weekday() + 6) % 7 - 3)\n",
    "    most_recent = check_day - datetime.timedelta(offset)\n",
    "    if most_recent not in holidays:\n",
    "        return most_recent\n",
    "    else:\n",
    "        return previous_working_day(most_recent, holidays)\n",
    "\n",
    "def get_rebalance_dates(\n",
    "    start_date: datetime.datetime,\n",
    "    end_date: datetime.datetime,\n",
    "    period_length: datetime.timedelta\n",
    ") -> List[datetime.datetime]:\n",
    "    curr_date = start_date\n",
    "    dates = []\n",
    "    while curr_date < end_date:\n",
    "        dates.append(get_closest_previous_work_day(curr_date))\n",
    "        curr_date += period_length\n",
    "    return dates\n",
    "\n",
    "# Assumes data is already filtered by date\n",
    "def filter_stocks_by_universe(\n",
    "    df: pd.DataFrame,\n",
    "    stocks_universe: StockUniverse\n",
    ") -> pd.DataFrame:\n",
    "    if stocks_universe.value == StockUniverse.SMALL.value:\n",
    "        return df[df['marketcap'] < 1]\n",
    "    elif stocks_universe.value == StockUniverse.MID.value:\n",
    "        return df[(df['marketcap'] >= 1) & (df['marketcap'] <= 10)]\n",
    "    elif stocks_universe.value == StockUniverse.LARGE.value:\n",
    "        return df[(df['marketcap'] >= 10)]\n",
    "    else:\n",
    "        raise Exception(f'Unsupported stock universe {stocks_universe}')\n",
    "\n",
    "def sort_df_by_metric(\n",
    "    df: pd.DataFrame,\n",
    "    metric: EvaluationMetric\n",
    ") -> pd.DataFrame:\n",
    "    if metric.value == EvaluationMetric.EV_EBIT.value:\n",
    "        return df.sort_values(by='evebit')\n",
    "    elif metric.value == EvaluationMetric.P_E.value:\n",
    "        return df.sort_values(by='pe')\n",
    "    elif metric.value == EvaluationMetric.P_B.value:\n",
    "        return df.sort_values(by='pb')\n",
    "    elif metric.value == EvaluationMetric.DIV_YIELD.value:\n",
    "        raise Exception('EvaluationMetric.DIV_YIELD not yet supported.')\n",
    "    else:\n",
    "        raise Exception(f'Unsupported evaluation metric {metric}')\n",
    "\n",
    "# Assumes df is sorted appropriately ahead of time.\n",
    "def get_top_n_stocks_by_metric(\n",
    "    df: pd.DataFrame,\n",
    "    n: int,\n",
    "    metric: EvaluationMetric    \n",
    ") -> List[str]:\n",
    "    df_res = None\n",
    "    if metric.value == EvaluationMetric.EV_EBIT.value:\n",
    "        df_res = df[(df['evebit'] > 0) & (df['ev'] > 0)]\n",
    "    elif metric.value == EvaluationMetric.P_E.value:\n",
    "        df_res = df[df['pe'] > 0]\n",
    "    elif metric.value == EvaluationMetric.P_B.value:\n",
    "        df_res = df[df['pb'] > 0]\n",
    "    elif metric.value == EvaluationMetric.DIV_YIELD.value:\n",
    "        raise Exception('EvaluationMetric.DIV_YIELD not yet supported.')\n",
    "    else:\n",
    "        raise Exception(f'Unsupported evaluation metric {metric}')\n",
    "    \n",
    "    return list(df_res[:n]['ticker'])\n",
    "\n",
    "def filter_df_by_date(\n",
    "    df: pd.DataFrame,\n",
    "    date: datetime.datetime\n",
    ") -> pd.DataFrame:\n",
    "    return df[df.date == date.strftime('%Y-%m-%d')]\n",
    "\n",
    "def get_stock_basket_price(\n",
    "    df: pd.DataFrame,\n",
    "    tickers: List[str]\n",
    ") -> int:\n",
    "    stocks_of_interest = df.loc[df['ticker'].isin(tickers)]\n",
    "    assert len(tickers) >= len(stocks_of_interest)\n",
    "    if len(stocks_of_interest) != len(tickers):\n",
    "        print(date, ' Stocks closed: ', set(tickers) - set(stocks_of_interest['ticker']))\n",
    "    return round(stocks_of_interest['price'].sum(), 2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eaf4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(EvaluationMetric.EV_EBIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Inputs for Base + Test\n",
    "\n",
    "INITIAL_PORTFOLIO_VALUE = 10000\n",
    "PORTFOLIO_SIZE = 30\n",
    "\n",
    "base_metric = EvaluationMetric.EV_EBIT\n",
    "test_metric = EvaluationMetric.P_B\n",
    "stocks_universe = StockUniverse.LARGE\n",
    "\n",
    "start_date = datetime.datetime.strptime(min(daily_data['date']), '%Y-%m-%d')\n",
    "end_date = datetime.datetime.strptime(max(daily_data['date']), '%Y-%m-%d')\n",
    "rebalance_dates = get_rebalance_dates(start_date, end_date, timedelta(days=90))\n",
    "\n",
    "# Optimization: Sorting every time would take too long\n",
    "base_sorted_daily_data = sort_df_by_metric(daily_data, base_metric)\n",
    "test_sorted_daily_data = sort_df_by_metric(daily_data, test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb05402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Results for Base + Test\n",
    "\n",
    "base_portfolio_value = INITIAL_PORTFOLIO_VALUE\n",
    "test_portfolio_value = INITIAL_PORTFOLIO_VALUE\n",
    "portfolio_size = PORTFOLIO_SIZE\n",
    "\n",
    "start_date = rebalance_dates[0]\n",
    "\n",
    "base_sorted_df = filter_df_by_date(base_sorted_daily_data, start_date)\n",
    "test_sorted_df = filter_df_by_date(test_sorted_daily_data, start_date)\n",
    "\n",
    "base_sorted_df = filter_stocks_by_universe(base_sorted_df, stocks_universe)\n",
    "test_sorted_df = filter_stocks_by_universe(test_sorted_df, stocks_universe)\n",
    "\n",
    "base_portfolio = get_top_n_stocks_by_metric(base_sorted_df, portfolio_size, base_metric)\n",
    "test_portfolio = get_top_n_stocks_by_metric(test_sorted_df, portfolio_size, test_metric)\n",
    "\n",
    "base_price = get_stock_basket_price(base_sorted_df, base_portfolio)\n",
    "test_price = get_stock_basket_price(test_sorted_df, test_portfolio)    \n",
    "\n",
    "res = {}\n",
    "res[start_date] = {\n",
    "    'base_basket_price': base_price,\n",
    "    'base_portfolio_value': base_portfolio_value,\n",
    "    'test_basket_price': test_price,\n",
    "    'test_portfolio_value': test_portfolio_value,        \n",
    "}\n",
    "\n",
    "for date in rebalance_dates:\n",
    "    print(date)\n",
    "\n",
    "    prev_base_price = base_price\n",
    "    prev_test_price = test_price    \n",
    "    \n",
    "    base_sorted_df = filter_df_by_date(base_sorted_daily_data, date)\n",
    "    test_sorted_df = filter_df_by_date(test_sorted_daily_data, date)\n",
    "    \n",
    "    base_price = get_stock_basket_price(base_sorted_df, base_portfolio)\n",
    "    test_price = get_stock_basket_price(test_sorted_df, test_portfolio)\n",
    "    \n",
    "    base_change = base_price / prev_base_price\n",
    "    test_change = test_price / prev_test_price\n",
    "    \n",
    "    base_portfolio_value = round(base_portfolio_value * base_change, 2)\n",
    "    test_portfolio_value = round(test_portfolio_value * test_change, 2)    \n",
    "    \n",
    "    res[date] = {\n",
    "        'base_basket_price': base_price,\n",
    "        'base_portfolio_value': base_portfolio_value,\n",
    "        'test_basket_price': test_price,\n",
    "        'test_portfolio_value': test_portfolio_value,        \n",
    "    }\n",
    "\n",
    "    base_sorted_df = filter_stocks_by_universe(base_sorted_df, stocks_universe)\n",
    "    test_sorted_df = filter_stocks_by_universe(test_sorted_df, stocks_universe)    \n",
    "    \n",
    "    base_portfolio = get_top_n_stocks_by_metric(base_sorted_df, portfolio_size, base_metric)\n",
    "    test_portfolio = get_top_n_stocks_by_metric(test_sorted_df, portfolio_size, test_metric)\n",
    "\n",
    "    base_price = get_stock_basket_price(base_sorted_df, base_portfolio)\n",
    "    test_price = get_stock_basket_price(test_sorted_df, test_portfolio)\n",
    "\n",
    "    \n",
    "df_res = pd.DataFrame.from_dict(res, orient='index')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e51013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot = df_res[['base_portfolio_value', 'test_portfolio_value']]\n",
    "df_to_plot.plot(title=f'{str(base_metric)} (base) vs {str(test_metric)} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73040",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data[daily_data.ticker == 'AAPL'][['date', 'price']].set_index('date').sort_values(by=['date']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55890dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data[daily_data.ticker == 'AAPL'].set_index('date').sort_values(by=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = datetime.datetime.strptime('2011-07-01', '%Y-%m-%d')\n",
    "# d2 = datetime.datetime.strptime('2011-09-30', '%Y-%m-%d')\n",
    "\n",
    "# get_stock_basket_price(base_sorted_df, d1, tickers)\n",
    "# get_stock_basket_price(base_sorted_df, d2, tickers)\n",
    "\n",
    "# date_data = base_sorted_df[base_sorted_df.date == d1.strftime('%Y-%m-%d')]\n",
    "# stocks_of_interest = date_data.loc[date_data['ticker'].isin(tickers)]\n",
    "# stocks_of_interest\n",
    "\n",
    "# date_data = base_sorted_df[base_sorted_df.date == d2.strftime('%Y-%m-%d')]\n",
    "# stocks_of_interest = date_data.loc[date_data['ticker'].isin(tickers)]\n",
    "# stocks_of_interest\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdfe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tip_env",
   "language": "python",
   "name": "tip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
